import csv
import json
import re
from pathlib import Path
from datetime import datetime, timedelta

class ArtifactTagger:
    def __init__(self):
        # íŒŒì¼ í™•ì¥ìë³„ í¬ë§· ë§¤í•‘
        self.format_map = {
            'FORMAT_DOCUMENT': ['.doc', '.docx', '.pdf', '.txt', '.rtf', '.hwp', '.xls', '.xlsx', '.ppt', '.pptx', '.odt', '.ods'],
            'FORMAT_IMAGE': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.ico', '.svg', '.webp', '.tif', '.tiff', '.raw'],
            'FORMAT_VIDEO': ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.mpg', '.mpeg', '.3gp'],
            'FORMAT_AUDIO': ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.wma', '.m4a', '.opus'],
            'FORMAT_ARCHIVE': ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.iso', '.cab', '.arj'],
            'FORMAT_EXECUTABLE': ['.exe', '.dll', '.sys', '.bat', '.cmd', '.msi', '.com', '.scr'],
            'FORMAT_SCRIPT': ['.ps1', '.vbs', '.js', '.py', '.sh', '.php', '.rb', '.pl', '.psm1'],
            'FORMAT_DATABASE': ['.db', '.sqlite', '.mdb', '.accdb', '.dbf', '.sdf'],
            'FORMAT_LOG': ['.log', '.evtx', '.evt', '.etl'],
            'FORMAT_CONFIG': ['.ini', '.conf', '.cfg', '.xml', '.json', '.yaml', '.yml', '.toml']
        }
        
        # ê²½ë¡œë³„ ì‹œìŠ¤í…œ ì˜ì—­ ë§¤í•‘
        self.area_patterns = {
            'AREA_SYSTEM32': r'(?i)\\system32\\|\\syswow64\\',
            'AREA_USER_DESKTOP': r'(?i)\\desktop\\',
            'AREA_USER_DOCUMENTS': r'(?i)\\documents\\|\\my documents\\',
            'AREA_USER_DOWNLOADS': r'(?i)\\downloads\\',
            'AREA_APPDATA_LOCAL': r'(?i)\\appdata\\local\\',
            'AREA_APPDATA_ROAMING': r'(?i)\\appdata\\roaming\\',
            'AREA_PROGRAMFILES': r'(?i)\\program files\\|\\program files \(x86\)\\',
            'AREA_PROGRAMDATA': r'(?i)\\programdata\\',
            'AREA_TEMP': r'(?i)\\temp\\|\\tmp\\|\\temporary\\',
            'AREA_NETWORK_RELATED': r'(?i)\\network\\|\\share\\|\\smb\\|\\netlogon\\',
            'AREA_SECURITY_RELATED': r'(?i)\\security\\|\\firewall\\|\\defender\\|\\windowsdefender\\'
        }
        
        # ë³´ì•ˆ ê´€ë ¨ íŒ¨í„´
        self.security_patterns = {
            'SEC_SUSPICIOUS_NAME': r'(?i)(crack|keygen|patch|hack|payload|malware|trojan|virus|ransomware|backdoor|rootkit|mimikatz|pwdump)',
            'SEC_SUSPICIOUS_PATH': r'(?i)\\temp\\.*\.exe|\\downloads\\.*\.exe|\\appdata\\local\\temp\\.*\.exe',
            'SEC_PERSISTENCE_PATH': r'(?i)\\startup\\|\\run\\|\\runonce\\|\\userinit|\\winlogon',
            'SEC_STARTUP': r'(?i)\\startup\\|\\start menu\\.*\\startup',
            'SEC_TASK_SCHEDULED': r'(?i)\\tasks\\|\\schedlgu\.txt|\\at\.exe',
            'SEC_FIREWALL_RELATED': r'(?i)firewall|\\wf\.msc|\\netsh|\\advfirewall'
        }
        
        # ì‚¬ìš©ì í™œë™ íŒ¨í„´
        self.activity_patterns = {
            'ACT_DOWNLOAD': r'(?i)\\downloads\\|\.crdownload$|\.download$|\.part$',
            'ACT_UPLOAD': r'(?i)\\uploads\\|\\outbox\\|\\sent\\',
            'ACT_INSTALL': r'(?i)\\installer|setup\.exe|install\.exe|\\msi\\|unattend\.xml',
            'ACT_UNINSTALL': r'(?i)uninstall|\\unins|\\remove|uninst\.exe',
            'ACT_EXECUTE': r'(?i)\.exe$|\.bat$|\.cmd$|\.com$|\.scr$',
            'ACT_COMMUNICATION': r'(?i)\\mail|\\outlook|\\thunderbird|\\skype|\\teams|\\slack|\\discord|\\zoom|\\telegram'
        }
        
        # ì•„í‹°íŒ©íŠ¸ íƒ€ì… íŒ¨í„´
        self.artifact_patterns = {
            'ARTIFACT_REGISTRY': r'(?i)\.reg$|\\registry\\|ntuser\.dat|sam$|system$|software$|security$',
            'ARTIFACT_EVENT_LOG': r'(?i)\.evtx$|\.evt$|\\winevt\\|\\eventlog\\',
            'ARTIFACT_PREFETCH': r'(?i)\\prefetch\\.*\.pf$',
            'ARTIFACT_LNK': r'(?i)\.lnk$',
            'ARTIFACT_BROWSER_HISTORY': r'(?i)\\history|\\places\.sqlite|\\webdata|\\visited',
            'ARTIFACT_COOKIE': r'(?i)\\cookies|\.cookie',
            'ARTIFACT_CACHE': r'(?i)\\cache\\|\\webcache\\',
            'ARTIFACT_EMAIL': r'(?i)\.pst$|\.ost$|\.eml$|\.msg$|\.mbox$',
            'ARTIFACT_DB': r'(?i)\.db$|\.sqlite$|\.sqlite3$'
        }
        
        # íŒŒì¼ ì‘ì—… í‚¤ì›Œë“œ (ì´ë²¤íŠ¸ ì„¤ëª…ì´ë‚˜ ë©”ëª¨ í•„ë“œìš©)
        self.file_operation_keywords = {
            'FILE_CREATE': r'(?i)creat|new file|file creat|created',
            'FILE_MODIFY': r'(?i)modif|change|edit|update|alter|written',
            'FILE_DELETE': r'(?i)delet|remov|erase',
            'FILE_RENAME': r'(?i)renam|name chang',
            'FILE_MOVE': r'(?i)move|relocat|transfer',
            'FILE_COPY': r'(?i)cop|duplicat',
            'FILE_ACCESS': r'(?i)access|open|read|view'
        }

    def tag_file_format(self, filename):
        """íŒŒì¼ í¬ë§· íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        ext = Path(filename).suffix.lower()
        
        for format_tag, extensions in self.format_map.items():
            if ext in extensions:
                tags.append(format_tag)
        
        return tags

    def tag_system_area(self, filepath):
        """ì‹œìŠ¤í…œ ì˜ì—­ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        
        for area_tag, pattern in self.area_patterns.items():
            if re.search(pattern, filepath):
                tags.append(area_tag)
        
        return tags

    def tag_security(self, filepath, filename):
        """ë³´ì•ˆ ê´€ë ¨ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        full_path = filepath + filename
        
        # ì‹¤í–‰ íŒŒì¼ ì²´í¬
        if filename.lower().endswith(('.exe', '.dll', '.sys', '.com', '.scr')):
            tags.append('SEC_EXECUTABLE')
        
        # ìˆ¨ê¹€ ì‹¤í–‰ íŒŒì¼
        if filename.lower().endswith(('.exe', '.dll', '.sys')) and (
            'hidden' in full_path.lower() or 
            re.search(r'(?i)^\.|\\\.', filename)
        ):
            tags.append('SEC_HIDDEN_EXECUTABLE')
        
        # íŒ¨í„´ ê¸°ë°˜ ë³´ì•ˆ íƒœê·¸
        for sec_tag, pattern in self.security_patterns.items():
            if re.search(pattern, full_path):
                tags.append(sec_tag)
        
        return tags

    def tag_user_activity(self, filepath, filename):
        """ì‚¬ìš©ì í™œë™ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        full_path = filepath + filename
        
        for act_tag, pattern in self.activity_patterns.items():
            if re.search(pattern, full_path):
                tags.append(act_tag)
        
        return tags

    def tag_artifact_type(self, filepath, filename):
        """ì•„í‹°íŒ©íŠ¸ íƒ€ì… íƒœê·¸ ì¶”ì¶œ"""
        tags = ['ARTIFACT_FILE']  # ê¸°ë³¸ íƒœê·¸
        full_path = filepath + filename
        
        for artifact_tag, pattern in self.artifact_patterns.items():
            if re.search(pattern, full_path):
                tags.append(artifact_tag)
        
        return tags

    def tag_timeline(self, created_time, modified_time, accessed_time):
        """ì‹œê°„ ê¸°ë°˜ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        now = datetime.now()
        
        # ë‚ ì§œ íŒŒì‹± ì‹œë„ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        times = []
        for time_str in [created_time, modified_time, accessed_time]:
            if not time_str or str(time_str).strip().upper() in ['N/A', 'NULL', '', 'NONE']:
                continue
            try:
                # ISO í˜•ì‹
                parsed_time = datetime.fromisoformat(str(time_str).replace('Z', '+00:00').split('+')[0].split('.')[0])
                times.append(parsed_time)
            except:
                try:
                    # ì¼ë°˜ì ì¸ í˜•ì‹ë“¤ ì‹œë„
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%m/%d/%Y %H:%M:%S', '%d/%m/%Y %H:%M:%S']:
                        try:
                            parsed_time = datetime.strptime(str(time_str).split('.')[0], fmt)
                            times.append(parsed_time)
                            break
                        except:
                            continue
                except:
                    pass
        
        if times:
            # ê°€ì¥ ìµœê·¼ ì‹œê°„ ê¸°ì¤€
            latest_time = max(times)
            time_diff = now - latest_time
            
            if time_diff <= timedelta(days=7):
                tags.append('TIME_RECENT')
            elif time_diff <= timedelta(days=30):
                tags.append('TIME_WEEK')
            elif time_diff <= timedelta(days=90):
                tags.append('TIME_MONTH')
            else:
                tags.append('TIME_OLD')
        
        # MAC íƒ€ì„ íƒœê·¸
        if created_time and str(created_time).strip().upper() not in ['N/A', 'NULL', '', 'NONE']:
            tags.append('TIME_CREATED_TIME')
        if modified_time and str(modified_time).strip().upper() not in ['N/A', 'NULL', '', 'NONE']:
            tags.append('TIME_MODIFIED_TIME')
        if accessed_time and str(accessed_time).strip().upper() not in ['N/A', 'NULL', '', 'NONE']:
            tags.append('TIME_ACCESSED_TIME')
        
        return tags

    def tag_file_operation(self, row):
        """íŒŒì¼ ì‘ì—… ë° ìƒíƒœ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        
        # ëª¨ë“  í•„ë“œë¥¼ í•©ì³ì„œ ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        search_text = ' '.join([str(v).lower() for v in row.values() if v])
        
        # íŒŒì¼ ì‘ì—… íƒœê·¸ (ì´ë²¤íŠ¸ ì„¤ëª…, ë©”ëª¨, ì½”ë©˜íŠ¸ ë“±ì—ì„œ)
        for operation_tag, pattern in self.file_operation_keywords.items():
            if re.search(pattern, search_text):
                tags.append(operation_tag)
        
        # íŒŒì¼ ì†ì„± íƒœê·¸
        attributes = row.get('attributes', row.get('attribute', row.get('attr', ''))).lower()
        if 'hidden' in attributes or 'h' in attributes.split():
            tags.append('FILE_HIDDEN')
        if 'system' in attributes or 's' in attributes.split():
            tags.append('FILE_SYSTEM')
        if 'temp' in attributes or 'temporary' in search_text:
            tags.append('FILE_TEMP')
        if 'encrypted' in attributes or 'encrypt' in search_text:
            tags.append('FILE_ENCRYPTED')
        if 'compressed' in attributes or 'compress' in search_text:
            tags.append('FILE_COMPRESSED')
        
        # íŒŒì¼ ìƒíƒœ íƒœê·¸
        deleted_field = str(row.get('deleted', row.get('is_deleted', row.get('status', '')))).lower()
        allocated_field = str(row.get('allocated', row.get('is_allocated', ''))).lower()
        slack_field = str(row.get('slack', row.get('file_slack', ''))).lower()
        recovered_field = str(row.get('recovered', row.get('is_recovered', ''))).lower()
        
        # ì‚­ì œ ì—¬ë¶€
        if deleted_field in ['true', '1', 'yes', 'deleted'] or 'delete' in search_text:
            tags.append('FILE_DELETED')
        else:
            tags.append('FILE_ACTIVE')
        
        # ë³µêµ¬ë¨
        if recovered_field in ['true', '1', 'yes', 'recovered'] or 'recover' in search_text:
            tags.append('FILE_RECOVERED')
        
        # í• ë‹¹ë˜ì§€ ì•ŠìŒ
        if allocated_field in ['false', '0', 'no', 'unallocated'] or 'unallocated' in search_text:
            tags.append('FILE_UNALLOCATED')
        
        # ìŠ¬ë™ ì˜ì—­
        if slack_field in ['true', '1', 'yes'] or 'slack' in search_text:
            tags.append('FILE_SLACK')
        
        return tags

    def process_csv(self, input_csv, output_jsonl):
        """CSV íŒŒì¼ì„ ì½ì–´ íƒœê·¸ë¥¼ ë¶™ì´ê³  JSONLë¡œ ì €ì¥"""
        results = []
        
        with open(input_csv, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                # í•„ë“œ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì§€ì›)
                filename = row.get('filename', row.get('name', row.get('file_name', row.get('file', ''))))
                filepath = row.get('filepath', row.get('path', row.get('file_path', row.get('full_path', ''))))
                created = row.get('created', row.get('created_time', row.get('creation_time', row.get('ctime', ''))))
                modified = row.get('modified', row.get('modified_time', row.get('modification_time', row.get('mtime', ''))))
                accessed = row.get('accessed', row.get('accessed_time', row.get('access_time', row.get('atime', ''))))
                
                # ê²½ë¡œì™€ íŒŒì¼ëª… ê²°í•©
                if not filepath and filename:
                    filepath = ''
                elif filepath and not filepath.endswith('\\') and not filepath.endswith('/'):
                    if '\\' in filepath or '/' in filepath:
                        pass  # ì´ë¯¸ ì „ì²´ ê²½ë¡œ
                    else:
                        filepath = filepath + '\\'
                
                # ëª¨ë“  íƒœê·¸ ìˆ˜ì§‘
                tags = []
                tags.extend(self.tag_file_format(filename))
                tags.extend(self.tag_system_area(filepath))
                tags.extend(self.tag_security(filepath, filename))
                tags.extend(self.tag_user_activity(filepath, filename))
                tags.extend(self.tag_artifact_type(filepath, filename))
                tags.extend(self.tag_timeline(created, modified, accessed))
                tags.extend(self.tag_file_operation(row))
                
                # ì¤‘ë³µ ì œê±°
                tags = list(set(tags))
                
                # ê²°ê³¼ ê°ì²´ ìƒì„±
                result = {
                    'original_data': row,
                    'tags': sorted(tags),  # ì •ë ¬í•˜ì—¬ ë³´ê¸° ì‰½ê²Œ
                    'tag_count': len(tags),
                    'categories': self.categorize_tags(tags)
                }
                
                results.append(result)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
        with open(output_jsonl, 'w', encoding='utf-8') as f:
            for result in results:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ í•­ëª©")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_jsonl}")
        
        # í†µê³„ ì¶œë ¥
        self.print_statistics(results)
        
        return results

    def categorize_tags(self, tags):
        """íƒœê·¸ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            'file_system': [],
            'file_format': [],
            'system_area': [],
            'artifact_type': [],
            'security': [],
            'timeline': [],
            'user_activity': []
        }
        
        for tag in tags:
            if tag.startswith('FILE_'):
                categories['file_system'].append(tag)
            elif tag.startswith('FORMAT_'):
                categories['file_format'].append(tag)
            elif tag.startswith('AREA_'):
                categories['system_area'].append(tag)
            elif tag.startswith('ARTIFACT_'):
                categories['artifact_type'].append(tag)
            elif tag.startswith('SEC_'):
                categories['security'].append(tag)
            elif tag.startswith('TIME_'):
                categories['timeline'].append(tag)
            elif tag.startswith('ACT_'):
                categories['user_activity'].append(tag)
        
        # ë¹ˆ ì¹´í…Œê³ ë¦¬ ì œê±°
        return {k: v for k, v in categories.items() if v}

    def print_statistics(self, results):
        """íƒœê·¸ í†µê³„ ì¶œë ¥"""
        tag_counts = {}
        category_counts = {
            'FILE_*': 0,
            'FORMAT_*': 0,
            'AREA_*': 0,
            'ARTIFACT_*': 0,
            'SEC_*': 0,
            'TIME_*': 0,
            'ACT_*': 0
        }
        
        for result in results:
            for tag in result['tags']:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
                
                # ì¹´í…Œê³ ë¦¬ë³„ ì¹´ìš´íŠ¸
                prefix = tag.split('_')[0] + '_*'
                if prefix in category_counts:
                    category_counts[prefix] += 1
        
        print("\n" + "="*60)
        print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ íƒœê·¸ í†µê³„")
        print("="*60)
        for category, count in sorted(category_counts.items()):
            print(f"  {category:15} : {count:5} ê°œ")
        
        print("\n" + "="*60)
        print("ğŸ“Š ìƒìœ„ 20ê°œ íƒœê·¸")
        print("="*60)
        for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:20]:
            print(f"  {tag:30} : {count:5} ê°œ")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import glob
    import os
    
    tagger = ArtifactTagger()
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
    csv_files = glob.glob("*.csv")
    
    if not csv_files:
        print("âŒ í˜„ì¬ ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"ğŸ“‚ ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ\n")
        
        total_processed = 0
        success_count = 0
        
        for csv_file in csv_files:
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {csv_file}")
            print(f"{'='*60}")
            
            # ì¶œë ¥ íŒŒì¼ëª… ìƒì„± (ì›ë³¸ëª…_tagged.jsonl)
            base_name = os.path.splitext(csv_file)[0]
            output_file = f"{base_name}_tagged.jsonl"
            
            try:
                results = tagger.process_csv(csv_file, output_file)
                total_processed += len(results)
                success_count += 1
                print(f"âœ… ì™„ë£Œ: {csv_file} â†’ {output_file}")
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({csv_file}): {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì „ì²´ ì²˜ë¦¬ ê²°ê³¼")
        print(f"{'='*60}")
        print(f"âœ… ì„±ê³µ: {success_count}/{len(csv_files)} íŒŒì¼")
        print(f"ğŸ“ ì´ ì²˜ë¦¬ í•­ëª©: {total_processed}ê°œ")
        print(f"{'='*60}")
