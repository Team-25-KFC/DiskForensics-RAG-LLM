import threading
import traceback
import time

import psycopg2
from psycopg2.extras import DictCursor

from sentence_transformers import SentenceTransformer
from pymilvus import (
    connections,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
    utility,
)

from fastapi import FastAPI  # â˜… FastAPI ì¶”ê°€

# =========================
# 0. ì„¤ì •
# =========================

# PostgreSQL
DB_CONFIG = {
    "host": "localhost",
    "dbname": "forensic_db",
    "user": "forensic",
    "password": "change_me_strong_pw",
}

RESULT_TABLE = "forensic_keyword_results"

# Milvus
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"
MILVUS_COLLECTION = "tag_test"   # ğŸ‘ˆ ì»¬ë ‰ì…˜ ì´ë¦„

# sentence-transformers ëª¨ë¸
ST_MODEL_NAME = "sentence-transformers/all-MiniLM-L12-v2"

# all-MiniLM-L12-v2 â†’ 384ì°¨ì›
EMBED_DIM = 384

# ì›Œì»¤ ìˆ˜
NUM_WORKERS = 3

# í•œ ë²ˆì— ì²˜ë¦¬í•  PostgreSQL row ìˆ˜
BATCH_SIZE = 96

# description + type/time/tag í•©ì¹œ text 4000ì ì œí•œ
MAX_TEXT_LEN = 4000


# =========================
# ê³µí†µ ë¡œê·¸ í•¨ìˆ˜
# =========================
def log(level, who, msg):
    print(f"[{level}][{who}] {msg}")


# =========================
# 1. SentenceTransformer ëª¨ë¸ ë¡œë”© (ì „ì—­ ê³µìœ )
# =========================
log("INFO", "MAIN", f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {ST_MODEL_NAME}")
model = SentenceTransformer(ST_MODEL_NAME)
model.max_seq_length = 512  # ìµœëŒ€ 512 í† í°
log("INFO", "MAIN", "ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


# =========================
# 2. Milvus ì—°ê²° & ì»¬ë ‰ì…˜ ì¤€ë¹„
# =========================
def init_milvus():
    log("INFO", "MAIN", f"Milvus ì—°ê²° ì‹œë„: {MILVUS_HOST}:{MILVUS_PORT}")
    connections.connect(
        alias="default",
        host=MILVUS_HOST,
        port=MILVUS_PORT,
    )
    log("INFO", "MAIN", "Milvus ì—°ê²° ì„±ê³µ")

    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ìˆìœ¼ë©´ ë“œë¡­
    if utility.has_collection(MILVUS_COLLECTION):
        log("INFO", "MAIN", f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ë°œê²¬ â†’ drop_collectionìœ¼ë¡œ ì‚­ì œ")
        utility.drop_collection(MILVUS_COLLECTION)

    # ìƒˆ ìŠ¤í‚¤ë§ˆ ì •ì˜: id, text, vector
    fields = [
        FieldSchema(
            name="id",
            dtype=DataType.INT64,
            is_primary=True,
            auto_id=False,
        ),
        FieldSchema(
            name="text",
            dtype=DataType.VARCHAR,
            max_length=MAX_TEXT_LEN,
        ),
        FieldSchema(
            name="vector",
            dtype=DataType.FLOAT_VECTOR,
            dim=EMBED_DIM,
        ),
    ]

    schema = CollectionSchema(
        fields=fields,
        description="Embeddings for forensic_keyword_results (id, text, vector)",
    )

    coll = Collection(
        name=MILVUS_COLLECTION,
        schema=schema,
        using="default",
    )

    log("INFO", "MAIN", f"ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ìƒˆë¡œ ìƒì„± ì™„ë£Œ (í•„ë“œ: id, text, vector)")

    # ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ìš©)
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE",
        "params": {"nlist": 1024},
    }
    log("INFO", "MAIN", "ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ...")
    coll.create_index(field_name="vector", index_params=index_params)
    log("INFO", "MAIN", "ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    # ë©”ëª¨ë¦¬ì— ë¡œë“œ
    coll.load()
    log("INFO", "MAIN", "ì»¬ë ‰ì…˜ load ì™„ë£Œ")


def get_collection():
    return Collection(MILVUS_COLLECTION)


# =========================
# 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (type / time / tag í¬í•¨)
# =========================
def build_text(row):
    """
    ì„ë² ë”©ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ êµ¬ì„±:
    - type
    - lastwritetimestamp
    - tag
    - description
    ì „ë¶€ í•©ì³ì„œ í•˜ë‚˜ì˜ textë¡œ ë§Œë“¤ê³ , 4000ì ì´ˆê³¼ ì‹œ ì˜ë¼ëƒ„.
    """
    t = row.get("type") or ""
    ts = row.get("lastwritetimestamp") or ""
    tag = row.get("tag") or ""
    desc = row.get("description") or ""

    parts = []
    if t:
        parts.append(f"[type] {t}")
    if ts:
        parts.append(f"[time] {ts}")
    if tag:
        parts.append(f"[tag] {tag}")
    if desc:
        parts.append(desc)

    text = " | ".join(parts)

    if len(text) > MAX_TEXT_LEN:
        text = text[:MAX_TEXT_LEN]

    return text


# =========================
# 4. ì›Œì»¤ í•¨ìˆ˜: id % NUM_WORKERS ê¸°ì¤€ ë¶„í• 
# =========================
def worker(worker_idx, summary_list):
    name = f"Worker-{worker_idx}"
    log("INFO", name, "ì‹œì‘")

    # PostgreSQL ì—°ê²°
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor(cursor_factory=DictCursor)
        log("INFO", name, "PostgreSQL ì—°ê²° ì„±ê³µ")
    except Exception as e:
        log("ERROR", name, f"PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        summary_list.append(f"[{name}] PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # Milvus ì»¬ë ‰ì…˜ í•¸ë“¤
    try:
        coll = get_collection()
    except Exception as e:
        log("ERROR", name, f"Milvus ì»¬ë ‰ì…˜ í•¸ë“¤ íšë“ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        conn.close()
        summary_list.append(f"[{name}] Milvus ì»¬ë ‰ì…˜ í•¸ë“¤ íšë“ ì‹¤íŒ¨: {e}")
        return

    last_id = 0
    total_processed = 0

    try:
        while True:
            cur.execute(
                f"""
                SELECT
                    id,
                    type,
                    lastwritetimestamp,
                    tag,
                    description
                FROM {RESULT_TABLE}
                WHERE id > %s
                  AND (id %% %s) = %s
                ORDER BY id
                LIMIT %s;
                """,
                (last_id, NUM_WORKERS, worker_idx, BATCH_SIZE),
            )
            rows = cur.fetchall()

            if not rows:
                log("INFO", name, f"ë” ì´ìƒ ì²˜ë¦¬í•  í–‰ ì—†ìŒ. ì¢…ë£Œ. (ì´ ì²˜ë¦¬ {total_processed} í–‰)")
                break

            last_id = rows[-1]["id"]
            batch_count = len(rows)
            total_processed += batch_count

            log("INFO", name, f"{batch_count}ê°œ row ì¡°íšŒ (last_id={last_id}, ëˆ„ì ={total_processed})")

            texts = []
            ids = []

            for r in rows:
                text = build_text(r)
                texts.append(text)
                ids.append(int(r["id"]))

            t0 = time.time()
            embeddings = model.encode(
                texts,
                batch_size=len(texts),
                convert_to_numpy=True,
                show_progress_bar=False,
            )
            t1 = time.time()

            log("INFO", name, f"ì„ë² ë”© ì™„ë£Œ ({batch_count}ê°œ, {t1 - t0:.2f}ì´ˆ ì†Œìš”)")

            data = [
                ids,
                texts,
                embeddings.tolist(),
            ]

            try:
                insert_result = coll.insert(data)
                log(
                    "INFO",
                    name,
                    f"Milvus insert ì™„ë£Œ ({batch_count}ê°œ) - ì˜ˆ: {insert_result.primary_keys[:3]}{'...' if len(insert_result.primary_keys) > 3 else ''}",
                )
            except Exception as e:
                log("ERROR", name, f"Milvus insert ì‹¤íŒ¨: {e}")
                traceback.print_exc()
                summary_list.append(f"[{name}] Milvus insert ì‹¤íŒ¨: {e}")

    except Exception as e:
        log("ERROR", name, f"worker ë‚´ë¶€ ì˜ˆì™¸: {e}")
        traceback.print_exc()
        summary_list.append(f"[{name}] worker ë‚´ë¶€ ì˜ˆì™¸: {e}")
    finally:
        try:
            conn.close()
            log("INFO", name, "PostgreSQL ì—°ê²° ì¢…ë£Œ")
        except Exception:
            pass

    log("INFO", name, f"ì¢…ë£Œ (ì´ ì²˜ë¦¬ {total_processed} í–‰)")
    summary_list.append(f"[{name}] ì´ ì²˜ë¦¬ {total_processed} í–‰")


# =========================
# 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =========================
def run_milvus_embedding_pipeline():
    main_summary = []

    try:
        init_milvus()
    except Exception as e:
        msg = f"Milvus ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
        log("ERROR", "MAIN", msg)
        traceback.print_exc()
        return msg

    total_rows = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute(f"SELECT COUNT(*) AS cnt FROM {RESULT_TABLE};")
            total_rows = cur.fetchone()["cnt"]
            msg = f"{RESULT_TABLE} ì´ í–‰ ìˆ˜: {total_rows}"
            log("INFO", "MAIN", msg)
            main_summary.append(msg)
    except Exception as e:
        msg = f"{RESULT_TABLE} ì´ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}"
        log("ERROR", "MAIN", msg)
        traceback.print_exc()
        main_summary.append(msg)
    finally:
        try:
            conn.close()
        except Exception:
            pass

    worker_summaries = []
    threads = []
    for idx in range(NUM_WORKERS):
        t = threading.Thread(
            target=worker,
            args=(idx, worker_summaries),
            name=f"Worker-{idx}",
        )
        threads.append(t)
        t.start()
        log("INFO", "MAIN", f"Worker-{idx} ì‹œì‘")

    for t in threads:
        t.join()
        log("INFO", "MAIN", f"{t.name} ì¢…ë£Œ í™•ì¸")

    log("INFO", "MAIN", "ëª¨ë“  ì›Œì»¤ ì‘ì—… ì™„ë£Œ")
    main_summary.append("ëª¨ë“  ì›Œì»¤ ì‘ì—… ì™„ë£Œ")

    try:
        coll = get_collection()
        milvus_count = coll.num_entities
        msg = f"Milvus ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ì—”í‹°í‹° ìˆ˜: {milvus_count}"
        log("INFO", "MAIN", msg)
        main_summary.append(msg)
    except Exception as e:
        msg = f"Milvus ì—”í‹°í‹° ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}"
        log("ERROR", "MAIN", msg)
        traceback.print_exc()
        main_summary.append(msg)

    lines = []
    lines.append("=== Milvus Embedding Pipeline Summary ===")
    if total_rows is not None:
        lines.append(f"- {RESULT_TABLE} ì´ í–‰ ìˆ˜: {total_rows}")
    lines.append("")

    lines.append("=== ë©”ì¸ ë¡œê·¸ ===")
    lines.extend(main_summary)
    lines.append("")

    lines.append("=== ì›Œì»¤ë³„ ìš”ì•½ ===")
    if worker_summaries:
        lines.extend(worker_summaries)
    else:
        lines.append("ì›Œì»¤ ìš”ì•½ ì—†ìŒ")

    return "\n".join(lines)


# =========================
# 6. FastAPI ì„œë²„ ì •ì˜  â˜…â˜… ì—¬ê¸°ê°€ í•µì‹¬
# =========================
app = FastAPI()

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/run-embed")
def run_embed():
    summary = run_milvus_embedding_pipeline()
    return {"status": "done", "summary": summary}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001, reload=False)