import os, json, csv, shutil
import subprocess
from typing import List, Dict, Any, Optional
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("forensic-mcp-server")


# ===============================================
# ìž‘ì—…ê³µê°„(ìƒŒë“œë°•ìŠ¤) ì„¤ì •: MCP_WORKSPACE í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
# ===============================================

# 1. í™˜ê²½ ë³€ìˆ˜ MCP_WORKSPACEì—ì„œ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
WORKSPACE_DIR = os.environ.get("MCP_WORKSPACE") 

if WORKSPACE_DIR:
    # í™˜ê²½ ë³€ìˆ˜ê°€ ìžˆìœ¼ë©´ ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •
    WORKSPACE_DIR = os.path.abspath(WORKSPACE_DIR)
else:
    # í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ì„ ê²½ìš° (ë¹„ìƒìš©), main.pyê°€ ìžˆëŠ” ê³³ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©
    WORKSPACE_DIR = os.path.abspath("../") 
    print(f"Warning: MCP_WORKSPACE env var not found. Using default: {WORKSPACE_DIR}")

# ì›Œí¬ìŠ¤íŽ˜ì´ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs(WORKSPACE_DIR, exist_ok=True)
print(f"MCP Server started. Workspace is set to: {WORKSPACE_DIR}")

def _resolve_in_workspace(rel_path: str) -> str:
    """Change the relative path based on mcp-server to the absolute path, and an exception occurs when leaving"""
    rel_path = rel_path or "."
    target = os.path.abspath(os.path.join(WORKSPACE_DIR, rel_path))
    # ë³´ì•ˆ ê²€ì‚¬: ì„¤ì •ëœ ì›Œí¬ìŠ¤íŽ˜ì´ìŠ¤ ë°–ìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì„ ë°©ì§€
    if os.path.commonpath([WORKSPACE_DIR, target]) != WORKSPACE_DIR:
        raise ValueError("Access denied: Path escapes workspace.")
    return target

def _ensure_parent_dir(path_abs: str):
    """Ensure the parent directory of the given path exists."""
    parent = os.path.dirname(path_abs) or WORKSPACE_DIR
    os.makedirs(parent, exist_ok=True)


# ===============================================
# ìœ í‹¸ë¦¬í‹° íˆ´ (íŒŒì¼/ë””ë ‰í† ë¦¬ ê´€ë¦¬)
# ===============================================
        
@mcp.tool()
def list_files(directory: str = ".") -> List[str]:
    """List of directories based on workspace ('.../')"""
    try:
        target = _resolve_in_workspace(directory)
        if not os.path.exists(target):
            return [f"Error: Directory '{directory}' not found."]
        if not os.path.isdir(target):
            return [f"Error: '{directory}' is not a directory."]
        return os.listdir(target)
    except Exception as e:
        return [f"An error occurred: {e}"]

@mcp.tool()
def make_dir(directory: str) -> str:
    """Create workspace reference directory (it's OK to exist)"""
    try:
        target = _resolve_in_workspace(directory)
        os.makedirs(target, exist_ok=True)
        return f"Directory ensured: '{directory}'."
    except Exception as e:
        return f"An error occurred: {e}"

@mcp.tool()
def read_file(filepath: str, encoding: str = "utf-8") -> str:
    """Read workspace reference file (director error)"""
    try:
        target = _resolve_in_workspace(filepath)
        if not os.path.exists(target):
            return f"Error: File '{filepath}' not found."
        if os.path.isdir(target):
            return f"Error: '{filepath}' is a directory, not a file."
        with open(target, "r", encoding=encoding) as f:
            return f.read()
    except Exception as e:
        return f"An error occurred: {e}"

@mcp.tool()
def write_file(filepath: str, content: str, encoding: str = "utf-8") -> str:
    """Write workspace reference file (overwrite). Reject directory path."""
    try:
        # ë””ë ‰í„°ë¦¬ë¡œ ëë‚˜ëŠ” ë¬¸ìžì—´ ì‚¬ì „ ì°¨ë‹¨
        if filepath.endswith(("/", "\\", os.path.sep)):
            return f"Error: '{filepath}' is a directory. Provide a file name."
        target = _resolve_in_workspace(filepath)
        if os.path.isdir(target):
            return f"Error: '{filepath}' is a directory. Provide a file name."
        _ensure_parent_dir(target)
        with open(target, "w", encoding=encoding) as f:
            f.write(content)
        return f"Successfully wrote to '{filepath}'."
    except Exception as e:
        return f"An error occurred: {e}"


# ì‚­ì œ íˆ´ (íŒŒì¼/ë””ë ‰í„°ë¦¬)

@mcp.tool()
def delete_file(filepath: str) -> str:
    """
    Delete 'file' based on workspace. Reject if you turn over the directory.
    Workspace root self-deletion is a defense.
    """
    try:
        target = _resolve_in_workspace(filepath)
        if target == WORKSPACE_DIR:
            return "Error: Refuse to delete workspace root."
        if not os.path.exists(target):
            return f"Error: '{filepath}' does not exist."
        if os.path.isdir(target):
            return f"Error: '{filepath}' is a directory. Use delete_dir for directories."
        os.remove(target)
        return f"Deleted file: '{filepath}'."
    except Exception as e:
        return f"An error occurred: {e}"

@mcp.tool()
def delete_dir(directory: str, recursive: bool = False) -> str:
    """
    Delete 'directory' based on workspace.
    - recurrent=False: delete only when empty
    - recurrent=True: Delete the entire contents (rmtree)
    Workspace root deletion is a defense.
    """
    try:
        target = _resolve_in_workspace(directory)
        if target == WORKSPACE_DIR:
            return "Error: Refuse to delete workspace root."
        if not os.path.exists(target):
            return f"Error: '{directory}' does not exist."
        if not os.path.isdir(target):
            return f"Error: '{directory}' is not a directory."
        if recursive:
            shutil.rmtree(target)
        else:
            os.rmdir(target)  # ë¹„ì–´ìžˆì§€ ì•Šìœ¼ë©´ OSError ë°œìƒ â†’ ì•ˆë‚´
        return f"Deleted directory: '{directory}'."
    except OSError as oe:
        return f"Error: Directory not empty or cannot remove without recursive=True. Detail: {oe}"
    except Exception as e:
        return f"An error occurred: {e}"


# ===============================================
# Autopsy CLI ë„êµ¬ë“¤
# ===============================================


@mcp.tool()
def analyze_e01_file(e01_file_path: str = None, case_name: str = None, case_base_dir: str = "E:\\lee\\db") -> str:
    """
    E01 íŒŒì¼ ë¶„ì„ ë˜ëŠ” ì¼€ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ
    - e01_file_pathê°€ ìžˆìœ¼ë©´: E01 â†’ DB â†’ JSON ë¶„ì„
    - e01_file_pathê°€ ì—†ìœ¼ë©´: ì¼€ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ
    """
    try:
        import sqlite3
        import json
        from datetime import datetime
        
        # ì¼€ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ëª¨ë“œ
        if not e01_file_path or not case_name:
            if not os.path.exists(case_base_dir):
                return f"Error: Case directory not found: {case_base_dir}"
            
            cases = []
            for item in os.listdir(case_base_dir):
                item_path = os.path.join(case_base_dir, item)
                if os.path.isdir(item_path):
                    db_path = os.path.join(item_path, "autopsy.db")
                    if os.path.exists(db_path):
                        cases.append({
                            "case_name": item,
                            "case_path": item_path,
                            "db_path": db_path,
                            "db_exists": True
                        })
                    else:
                        cases.append({
                            "case_name": item,
                            "case_path": item_path,
                            "db_path": db_path,
                            "db_exists": False
                        })
            
            return f"ðŸ“‹ Available Autopsy Cases:\n{json.dumps(cases, ensure_ascii=False, indent=2)}"
        
        # E01 ë¶„ì„ ëª¨ë“œ
        if not os.path.exists(e01_file_path):
            return f"Error: E01 file not found: {e01_file_path}"
        
        # ì¼€ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(case_base_dir, exist_ok=True)
        
        # 1. Autopsy ë¶„ì„ ì‹¤í–‰ (ì§ì ‘ êµ¬í˜„)
        autopsy_paths = [
            r"C:\Program Files\Autopsy-4.20.0\bin\autopsy64.exe",
            r"C:\Program Files\Autopsy\bin\autopsy64.exe",
            r"C:\Program Files (x86)\Autopsy\bin\autopsy64.exe",
            r"C:\Autopsy\bin\autopsy64.exe"
        ]
        
        autopsy_exe = None
        for path in autopsy_paths:
            if os.path.exists(path):
                autopsy_exe = path
                break
        
        if not autopsy_exe:
            return "Error: Autopsy not found. Please check installation path."
        
        # Autopsy CLI ëª…ë ¹ì–´ ì‹¤í–‰
        command = f'--createCase --caseName="{case_name}" --caseBaseDir="{case_base_dir}" --addDataSource --dataSourcePath="{e01_file_path}" --runIngest'
        full_command = f'"{autopsy_exe}" {command}'
        
        try:
            result = subprocess.run(full_command, shell=True, capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                autopsy_result = f"Autopsy CLI executed successfully:\n{result.stdout}"
            else:
                autopsy_result = f"Autopsy CLI error:\n{result.stderr}"
        except subprocess.TimeoutExpired:
            autopsy_result = "Error: Autopsy CLI command timed out (5 minutes)"
        except Exception as e:
            autopsy_result = f"Error running Autopsy CLI: {e}"
        
        # 2. ë¶„ì„ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if "error" in autopsy_result.lower() or "failed" in autopsy_result.lower():
            return f"Autopsy analysis failed:\n{autopsy_result}"
        
        # 3. ì¼€ì´ìŠ¤ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        case_dir = None
        for item in os.listdir(case_base_dir):
            if item.startswith(case_name):
                case_dir = os.path.join(case_base_dir, item)
                break
        
        if not case_dir:
            return f"Error: Case '{case_name}' not found in {case_base_dir}"
        
        # 4. Autopsy DB íŒŒì¼ ê²½ë¡œ
        db_path = os.path.join(case_dir, "autopsy.db")
        if not os.path.exists(db_path):
            return f"Error: autopsy.db not found at {db_path}"
        
        # 5. JSON ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        json_output_dir = os.path.join("E:\\lee\\json", case_name)
        os.makedirs(json_output_dir, exist_ok=True)
        
        # 6. SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° í†µí•© JSON ìƒì„±
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
        tables = [row[0] for row in cursor.fetchall()]
        
        # í†µí•© ë°ì´í„° êµ¬ì¡°
        unified_data = {
            "case_name": case_name,
            "conversion_date": datetime.now().isoformat(),
            "source_db": db_path,
            "total_tables": len(tables),
            "tables": {}
        }
        
        conversion_results = []
        non_empty_tables = 0
        
        for table_name in tables:
            try:
                # í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„° ì¡°íšŒ
                cursor.execute(f"SELECT * FROM {table_name}")
                rows = cursor.fetchall()
                
                # ë¹ˆ í…Œì´ë¸”ì€ ê±´ë„ˆë›°ê¸°
                if len(rows) == 0:
                    conversion_results.append(f"â­ï¸ {table_name}: Empty table (skipped)")
                    continue
                
                # ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                data = []
                for row in rows:
                    data.append(dict(row))
                
                # í†µí•© ë°ì´í„°ì— í…Œì´ë¸” ì¶”ê°€
                unified_data["tables"][table_name] = data
                non_empty_tables += 1
                
                conversion_results.append(f"âœ… {table_name}: {len(data)} rows")
                
            except Exception as e:
                conversion_results.append(f"âŒ {table_name}: Error - {e}")
        
        conn.close()
        
        # 7. í†µí•© JSON íŒŒì¼ë¡œ ì €ìž¥
        unified_json_path = os.path.join(json_output_dir, f"{case_name}_unified.json")
        with open(unified_json_path, 'w', encoding='utf-8') as f:
            json.dump(unified_data, f, ensure_ascii=False, indent=2, default=str)
        
        # 8. ë³€í™˜ ìš”ì•½ ìƒì„±
        summary = {
            "case_name": case_name,
            "conversion_date": datetime.now().isoformat(),
            "source_db": db_path,
            "output_file": unified_json_path,
            "total_tables": len(tables),
            "non_empty_tables": non_empty_tables,
            "empty_tables": len(tables) - non_empty_tables,
            "conversion_results": conversion_results
        }
        
        summary_file = os.path.join(json_output_dir, "unified_conversion_summary.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        return f"""âœ… Complete E01 Analysis & Unified JSON Conversion!

ðŸ” Autopsy Analysis:
{autopsy_result}

ðŸ“„ Unified JSON Conversion:
ðŸŽ¯ Conversion Completed!

ðŸ“Š Summary:
- Case: {case_name}
- Total tables: {len(tables)}
- Non-empty tables: {non_empty_tables}
- Empty tables: {len(tables) - non_empty_tables}

ðŸ“ Output:
- Unified JSON: {unified_json_path}
- Summary: {summary_file}

ðŸ“‹ Results:
{chr(10).join(conversion_results[:10])}{'...' if len(conversion_results) > 10 else ''}"""
        
    except Exception as e:
        return f"Error in complete E01 analysis workflow: {e}"



    
# ===============================================
# ì„œë²„ ì‹¤í–‰ (FastMCP í‘œì¤€)
# ===============================================

if __name__ == "__main__":
    mcp.run()
