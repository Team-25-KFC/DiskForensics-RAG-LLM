import os
import json
import logging
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from sentence_transformers import SentenceTransformer

# ======================
# ì„¤ì •
# ======================
JSON_PATH = r"C:\Users\aromi\ë°”íƒ• í™”ë©´\langflow\lang_flow\Persistence\tag.json"
COLLECTION_NAME = "forensic_tags_test"
DIM = 384  # embedding dimension for MiniLM-L12
BATCH_SIZE = 100

# ======================
# ë¡œê·¸ ì„¤ì •
# ======================
logging.basicConfig(
    filename="milvus_tag_upload.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def log(msg):
    print(msg)
    logging.info(msg)

# ======================
# 1ï¸âƒ£ Milvus ì—°ê²°
# ======================
connections.connect("default", host="localhost", port="19530")
log("âœ… Connected to Milvus")

if utility.has_collection(COLLECTION_NAME):
    utility.drop_collection(COLLECTION_NAME)
    log(f"ğŸ—‘ï¸ Existing collection '{COLLECTION_NAME}' dropped.")

# ======================
# 2ï¸âƒ£ ìŠ¤í‚¤ë§ˆ ì •ì˜
# ======================
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100),
    FieldSchema(name="subcategory", dtype=DataType.VARCHAR, max_length=150),
    FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="keywords", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=DIM)
]

schema = CollectionSchema(fields, description="Forensic Tag Embeddings Collection")
collection = Collection(name=COLLECTION_NAME, schema=schema)
log(f"ğŸ†• Created collection: {COLLECTION_NAME}")

# ======================
# 3ï¸âƒ£ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# ======================
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
log("ğŸ§  Loaded embedding model")

# ======================
# 4ï¸âƒ£ JSON ë¡œë“œ ë° ë°°ì¹˜ ì—…ë¡œë“œ
# ======================
with open(JSON_PATH, "r", encoding="utf-8") as f:
    tags = json.load(f)

log(f"ğŸ“„ Loaded {len(tags)} tags from JSON")

def batch(iterable, n=BATCH_SIZE):
    for i in range(0, len(iterable), n):
        yield iterable[i:i + n]

for chunk in batch(tags, BATCH_SIZE):
    categories = [
        item["category"] if isinstance(item["category"], str)
        else "|".join(item["category"])  # âœ… ë¦¬ìŠ¤íŠ¸ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
        for item in chunk
    ]
    subcategories = [item["subcategory"] for item in chunk]
    descriptions = [item["description"] for item in chunk]
    keywords = [", ".join(item["keywords"]) for item in chunk]

    texts_to_embed = [
        f"{c} - {s} : {d}. Keywords: {k}"
        for c, s, d, k in zip(categories, subcategories, descriptions, keywords)
    ]

    embeddings = model.encode(texts_to_embed, show_progress_bar=True, normalize_embeddings=True)

    data = [categories, subcategories, descriptions, keywords, embeddings]
    collection.insert(data)
    log(f"âœ… Inserted {len(chunk)} records")

collection.flush()
log("ğŸ’¾ All data flushed to Milvus")

# ======================
# 5ï¸âƒ£ ì¸ë±ìŠ¤ ìƒì„±
# ======================
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}
}

collection.create_index(field_name="embedding", index_params=index_params)
log("ğŸ“Š Index created successfully")

collection.load()
log("ğŸš€ Collection loaded and ready for query")