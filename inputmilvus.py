import os
import gc
import time
import logging
import pandas as pd
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pymilvus import connections, Collection, CollectionSchema, FieldSchema, DataType, utility
from sentence_transformers import SentenceTransformer

# ======================
# ì„¤ì •
# ======================
json_path = r"C:\Users\zlfnf\Desktop\q2wr423\243\view_useractivity.json"
collection_name = os.path.splitext(os.path.basename(json_path))[0]  # ex) view_system
dim = 384
BATCH_SIZE = 200
THREADS = 5

# ======================
# ë¡œê·¸ ì„¤ì •
# ======================
logging.basicConfig(
    filename="milvus_thread_log.txt",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

def log(msg):
    print(msg)
    logging.info(msg)

# ======================
# 1ï¸âƒ£ Milvus ì—°ê²°
# ======================
connections.connect("default", host="localhost", port="19530")
log("âœ… Connected to Milvus")

if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=dim),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
]
schema = CollectionSchema(fields, description="Forensic artifacts (threaded insert)")
collection = Collection(name=collection_name, schema=schema)
collection.create_index(field_name="vector", index_params={"metric_type": "IP", "index_type": "HNSW", "params": {"M": 8, "efConstruction": 64}})
log("âœ… Collection created")

# ======================
# 2ï¸âƒ£ JSON ë¡œë“œ + í…ìŠ¤íŠ¸ ë³€í™˜
# ======================
df = pd.read_json(json_path, orient="records")
df["all_columns_text"] = df.astype(str).apply(
    lambda row: " | ".join([f"{col}: {val}" for col, val in row.items()]),
    axis=1
)
texts = df["all_columns_text"].tolist()
ids = df.index.astype("int64").tolist()
log(f"ğŸ“¦ Loaded {len(texts)} rows")

# ======================
# 3ï¸âƒ£ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# ======================
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# ======================
# 4ï¸âƒ£ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„í• 
# ======================
batches = [(ids[i:i+BATCH_SIZE], texts[i:i+BATCH_SIZE]) for i in range(0, len(ids), BATCH_SIZE)]
log(f"ğŸ”¹ Total batches: {len(batches)} (Batch size: {BATCH_SIZE})")

# ======================
# 5ï¸âƒ£ ì“°ë ˆë“œ ì‘ì—… í•¨ìˆ˜
# ======================
def process_batch(batch_id, id_list, text_list):
    thread_name = threading.current_thread().name
    try:
        start = time.perf_counter()
        log(f"ğŸŸ¢ [START] Thread-{batch_id} ({thread_name}) â†’ Processing {len(id_list)} items...")

        # --- ì„ë² ë”© ---
        vectors = model.encode(text_list, batch_size=32, convert_to_numpy=True, show_progress_bar=False)
        mid_time = time.perf_counter()
        log(f"   â†³ [Thread-{batch_id}] Embedding done ({mid_time - start:.2f}s)")

        # --- Milvus ì‚½ì… ---
        collection.insert([id_list, vectors, text_list])
        collection.flush()

        elapsed = time.perf_counter() - start
        log(f"ğŸ”µ [END] Thread-{batch_id} ({thread_name}) âœ… Inserted {len(id_list)} items in {elapsed:.2f}s\n")
        gc.collect()
        return f"Thread-{batch_id} finished in {elapsed:.2f}s"
    except Exception as e:
        log(f"ğŸ”´ [ERROR] Thread-{batch_id} ({thread_name}) âŒ {e}")
        return str(e)

# ======================
# 6ï¸âƒ£ ì“°ë ˆë“œí’€ ì‹¤í–‰ + ìƒíƒœ ëª¨ë‹ˆí„°ë§
# ======================
start_total = time.perf_counter()
log(f"ğŸš€ Starting multi-threaded insert ({THREADS} threads)...")

with ThreadPoolExecutor(max_workers=THREADS) as executor:
    futures = {executor.submit(process_batch, i, b[0], b[1]): i for i, b in enumerate(batches)}

    active_threads = set()

    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    while any(future.running() for future in futures):
        current = [t.name for t in threading.enumerate() if t.name.startswith("ThreadPoolExecutor")]
        if current != active_threads:
            active_threads = set(current)
            log(f"âš™ï¸ Currently active threads: {list(active_threads)}")
        time.sleep(1)

    # ì™„ë£Œëœ ì‘ì—… ê²°ê³¼
    for future in as_completed(futures):
        result = future.result()
        print(result)

total_elapsed = time.perf_counter() - start_total
log(f"ğŸ All threads completed. Total time: {total_elapsed:.2f}s")
log(f"âœ… Final row count: {collection.num_entities}")
print(f"âœ… Total inserted: {collection.num_entities}")
