import threading
import traceback
import time

import psycopg2
from psycopg2.extras import DictCursor

from sentence_transformers import SentenceTransformer
from pymilvus import (
    connections,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
    utility,
)

# =========================
# 0. ì„¤ì •
# =========================

# PostgreSQL
DB_CONFIG = {
    "host": "localhost",
    "dbname": "forensic_db",
    "user": "postgres",
    "password": "admin123",
}

RESULT_TABLE = "forensic_keyword_results"

# Milvus
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"
MILVUS_COLLECTION = "tag_test"   # ğŸ‘ˆ ì»¬ë ‰ì…˜ ì´ë¦„

# sentence-transformers ëª¨ë¸
ST_MODEL_NAME = "sentence-transformers/all-MiniLM-L12-v2"

# all-MiniLM-L12-v2 â†’ 384ì°¨ì›
EMBED_DIM = 384

# ì›Œì»¤ ìˆ˜
NUM_WORKERS = 5

# í•œ ë²ˆì— ì²˜ë¦¬í•  PostgreSQL row ìˆ˜
# ğŸ‘‰ ë” ë¹ ë¥´ê²Œ í•˜ê³  ì‹¶ìœ¼ë©´ 64 â†’ 96, 128 ë“±ìœ¼ë¡œ ì˜¬ë ¤ì„œ í…ŒìŠ¤íŠ¸í•´ë´.
BATCH_SIZE = 96

# description + type/time/tag í•©ì¹œ text 4000ì ì œí•œ
MAX_TEXT_LEN = 4000


# =========================
# ê³µí†µ ë¡œê·¸ í•¨ìˆ˜
# =========================
def log(level, who, msg):
    print(f"[{level}][{who}] {msg}")


# =========================
# 1. SentenceTransformer ëª¨ë¸ ë¡œë”© (ì „ì—­ ê³µìœ )
# =========================
log("INFO", "MAIN", f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {ST_MODEL_NAME}")
model = SentenceTransformer(ST_MODEL_NAME)
model.max_seq_length = 512  # ìµœëŒ€ 512 í† í°
log("INFO", "MAIN", "ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")


# =========================
# 2. Milvus ì—°ê²° & ì»¬ë ‰ì…˜ ì¤€ë¹„
# =========================
def init_milvus():
    log("INFO", "MAIN", f"Milvus ì—°ê²° ì‹œë„: {MILVUS_HOST}:{MILVUS_PORT}")
    connections.connect(
        alias="default",
        host=MILVUS_HOST,
        port=MILVUS_PORT,
    )
    log("INFO", "MAIN", "Milvus ì—°ê²° ì„±ê³µ")

    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ìˆìœ¼ë©´ ë“œë¡­
    if utility.has_collection(MILVUS_COLLECTION):
        log("INFO", "MAIN", f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ë°œê²¬ â†’ drop_collectionìœ¼ë¡œ ì‚­ì œ")
        utility.drop_collection(MILVUS_COLLECTION)

    # ìƒˆ ìŠ¤í‚¤ë§ˆ ì •ì˜: id, text, vector
    fields = [
        FieldSchema(
            name="id",
            dtype=DataType.INT64,
            is_primary=True,
            auto_id=False,
        ),
        FieldSchema(
            name="text",
            dtype=DataType.VARCHAR,
            max_length=MAX_TEXT_LEN,
        ),
        FieldSchema(
            name="vector",
            dtype=DataType.FLOAT_VECTOR,
            dim=EMBED_DIM,
        ),
    ]

    schema = CollectionSchema(
        fields=fields,
        description="Embeddings for forensic_keyword_results (id, text, vector)",
    )

    coll = Collection(
        name=MILVUS_COLLECTION,
        schema=schema,
        using="default",
    )

    log("INFO", "MAIN", f"ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ìƒˆë¡œ ìƒì„± ì™„ë£Œ (í•„ë“œ: id, text, vector)")

    # ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ìš©)
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE",
        "params": {"nlist": 1024},
    }
    log("INFO", "MAIN", "ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ...")
    coll.create_index(field_name="vector", index_params=index_params)
    log("INFO", "MAIN", "ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    # ë©”ëª¨ë¦¬ì— ë¡œë“œ
    coll.load()
    log("INFO", "MAIN", "ì»¬ë ‰ì…˜ load ì™„ë£Œ")


def get_collection():
    return Collection(MILVUS_COLLECTION)


# =========================
# 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (type / time / tag í¬í•¨)
# =========================
def build_text(row):
    """
    ì„ë² ë”©ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ êµ¬ì„±:
    - type
    - lastwritetimestamp
    - tag
    - description
    ì „ë¶€ í•©ì³ì„œ í•˜ë‚˜ì˜ textë¡œ ë§Œë“¤ê³ , 4000ì ì´ˆê³¼ ì‹œ ì˜ë¼ëƒ„.
    """
    t = row.get("type") or ""
    ts = row.get("lastwritetimestamp") or ""
    tag = row.get("tag") or ""
    desc = row.get("description") or ""

    parts = []
    if t:
        parts.append(f"[type] {t}")
    if ts:
        parts.append(f"[time] {ts}")
    if tag:
        parts.append(f"[tag] {tag}")
    if desc:
        parts.append(desc)

    text = " | ".join(parts)

    # 4000ì ì´ˆê³¼ ì‹œ ì˜ë¼ë‚´ê¸° (Milvus VARCHAR max_lengthì™€ ë™ì¼)
    if len(text) > MAX_TEXT_LEN:
        text = text[:MAX_TEXT_LEN]

    return text


# =========================
# 4. ì›Œì»¤ í•¨ìˆ˜: id % NUM_WORKERS ê¸°ì¤€ ë¶„í• 
# =========================
def worker(worker_idx):
    name = f"Worker-{worker_idx}"
    log("INFO", name, "ì‹œì‘")

    # PostgreSQL ì—°ê²°
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor(cursor_factory=DictCursor)
        log("INFO", name, "PostgreSQL ì—°ê²° ì„±ê³µ")
    except Exception as e:
        log("ERROR", name, f"PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return

    # Milvus ì»¬ë ‰ì…˜ í•¸ë“¤
    try:
        coll = get_collection()
    except Exception as e:
        log("ERROR", name, f"Milvus ì»¬ë ‰ì…˜ í•¸ë“¤ íšë“ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        conn.close()
        return

    last_id = 0
    total_processed = 0

    try:
        while True:
            # ì´ ì›Œì»¤ê°€ ë‹´ë‹¹í•˜ëŠ” id (% NUM_WORKERS == worker_idx) ì¤‘
            # last_id ì´í›„ ê²ƒë§Œ ê°€ì ¸ì˜¤ê¸°
            cur.execute(
                f"""
                SELECT
                    id,
                    type,
                    lastwritetimestamp,
                    tag,
                    description
                FROM {RESULT_TABLE}
                WHERE id > %s
                  AND (id %% %s) = %s
                ORDER BY id
                LIMIT %s;
                """,
                (last_id, NUM_WORKERS, worker_idx, BATCH_SIZE),
            )
            rows = cur.fetchall()

            if not rows:
                log("INFO", name, f"ë” ì´ìƒ ì²˜ë¦¬í•  í–‰ ì—†ìŒ. ì¢…ë£Œ. (ì´ ì²˜ë¦¬ {total_processed} í–‰)")
                break

            last_id = rows[-1]["id"]
            batch_count = len(rows)
            total_processed += batch_count

            log("INFO", name, f"{batch_count}ê°œ row ì¡°íšŒ (last_id={last_id}, ëˆ„ì ={total_processed})")

            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            texts = []
            ids = []

            for r in rows:
                text = build_text(r)
                texts.append(text)
                ids.append(int(r["id"]))

            # ì„ë² ë”© ê³„ì‚°
            t0 = time.time()
            embeddings = model.encode(
                texts,
                batch_size=len(texts),  # í•œ ë²ˆì— ì´ batch ì „ë¶€
                convert_to_numpy=True,
                show_progress_bar=False,
            )
            t1 = time.time()

            log("INFO", name, f"ì„ë² ë”© ì™„ë£Œ ({batch_count}ê°œ, {t1 - t0:.2f}ì´ˆ ì†Œìš”)")

            # Milvusì— ì „ì†¡
            # í•„ë“œ ìˆœì„œ: id, text, vector
            data = [
                ids,
                texts,
                embeddings.tolist(),
            ]

            try:
                insert_result = coll.insert(data)
                # primary_keysëŠ” ìš°ë¦¬ê°€ ë„£ì€ id ê·¸ëŒ€ë¡œë¼ ì§§ê²Œë§Œ ì¶œë ¥
                log(
                    "INFO",
                    name,
                    f"Milvus insert ì™„ë£Œ ({batch_count}ê°œ) - ì˜ˆ: {insert_result.primary_keys[:3]}{'...' if len(insert_result.primary_keys) > 3 else ''}",
                )
            except Exception as e:
                log("ERROR", name, f"Milvus insert ì‹¤íŒ¨: {e}")
                traceback.print_exc()
                # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ë°°ì¹˜ ê³„ì†

    except Exception as e:
        log("ERROR", name, f"worker ë‚´ë¶€ ì˜ˆì™¸: {e}")
        traceback.print_exc()
    finally:
        try:
            conn.close()
            log("INFO", name, "PostgreSQL ì—°ê²° ì¢…ë£Œ")
        except Exception:
            pass

    log("INFO", name, f"ì¢…ë£Œ (ì´ ì²˜ë¦¬ {total_processed} í–‰)")


# =========================
# 5. main
# =========================
def main():
    # 1) Milvus ì´ˆê¸°í™” (ì»¬ë ‰ì…˜ ë“œë¡­ + ì¬ìƒì„± + ì¸ë±ìŠ¤/ë¡œë“œ)
    init_milvus()

    # 2) forensic_keyword_results ì´ ê°œìˆ˜ ì •ë³´ìš© ì¶œë ¥
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute(f"SELECT COUNT(*) AS cnt FROM {RESULT_TABLE};")
            cnt = cur.fetchone()["cnt"]
            log("INFO", "MAIN", f"{RESULT_TABLE} ì´ í–‰ ìˆ˜: {cnt}")
    except Exception as e:
        log("ERROR", "MAIN", f"ì´ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
    finally:
        try:
            conn.close()
        except Exception:
            pass

    # 3) ì›Œì»¤ NUM_WORKERSê°œ ì‹¤í–‰
    threads = []
    for idx in range(NUM_WORKERS):
        t = threading.Thread(target=worker, args=(idx,), name=f"Worker-{idx}")
        threads.append(t)
        t.start()
        log("INFO", "MAIN", f"Worker-{idx} ì‹œì‘")

    # 4) ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
    for t in threads:
        t.join()
        log("INFO", "MAIN", f"{t.name} ì¢…ë£Œ í™•ì¸")

    log("INFO", "MAIN", "ëª¨ë“  ì›Œì»¤ ì‘ì—… ì™„ë£Œ")


if __name__ == "__main__":
    main()
