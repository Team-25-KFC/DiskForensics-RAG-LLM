import psycopg2
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from sentence_transformers import SentenceTransformer

# ===============================
# 1ï¸âƒ£ DB ì„¤ì •
# ===============================
DB_CONFIG = {
    "host": "localhost",
    "dbname": "forensic_db",
    "user": "postgres",
    "password": "admin123",  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
}

# ===============================
# 2ï¸âƒ£ ì—¬ëŸ¬ ê°œì˜ íƒœê·¸ ì •ì˜
# ===============================
tags = [
    {
    "category": "System",
    "subcategory": "OS_Info",
    "description": "ìš´ì˜ì²´ì œ ë²„ì „, ë¹Œë“œ ë²ˆí˜¸, ì„¤ì¹˜ì¼ ë“± ì‹œìŠ¤í…œ ê¸°ë³¸ í™˜ê²½ ì •ë³´ë¥¼ í™•ì¸í•œë‹¤.",
    "keywords": ["SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion", "ProductName", "CurrentBuildNumber", "InstallDate", "RegisteredOwner"]
  }


]

# ===============================
# 3ï¸âƒ£ DB ì—°ê²°
# ===============================
conn = psycopg2.connect(**DB_CONFIG)
cur = conn.cursor()
# ===============================
# 4ï¸âƒ£ forensic í…Œì´ë¸” ì¡°íšŒ (ì „ì²´)
# ===============================
cur.execute("""
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema='public'
      AND table_name LIKE 'view_%'
    ORDER BY table_name;
""")
tables = [t[0] for t in cur.fetchall()]
print(f"ğŸ“‹ Found {len(tables)} tables:", ", ".join(tables))

matched_rows = []
summary = {}
total_hits = 0

# ===============================
# 5ï¸âƒ£ ê° íƒœê·¸ë³„ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
# ===============================
for tag in tags:
    print(f"\nğŸ” Searching for tag: {tag['subcategory']} ({tag['category']})")

    for table_name in tables:
        print(f"   â”” Table: {table_name}")
        cur.execute("""
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema='public' AND table_name=%s;
        """, (table_name,))
        columns = [c[0] for c in cur.fetchall()]
        has_event_col = "event_id" in columns

        hit_count = 0
        # (ì—¬ê¸° ì´í›„ëŠ” ê¸°ì¡´ ê²€ìƒ‰ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€)

        # -------------------------------
        # -------------------------------
        # (1) í‚¤ì›Œë“œ ê²€ìƒ‰ (exclude ì¡°ê±´ ì ìš©)
        # -------------------------------
        for kw in tag["keywords"]:
            exclude_conditions = " AND ".join(
                [f"full_description NOT ILIKE '%%{ex}%%'" for ex in tag.get("exclude_patterns", [])]
            )

            # âœ… "AND" í¬í•¨ í‚¤ì›Œë“œ ì²˜ë¦¬
            if "AND" in kw:
                parts = [p.strip() for p in kw.split("AND") if p.strip()]
                conditions = " AND ".join(
                    [f"(full_description ILIKE '%{p}%' OR artifact_name ILIKE '%{p}%' OR file_name ILIKE '%{p}%')" for p in parts]
                )
                query_kw = f"""
                    SELECT *
                    FROM {table_name}
                    WHERE {conditions}
                    {f'AND {exclude_conditions}' if exclude_conditions else ''};
                """
                cur.execute(query_kw)
            else:
                # ê¸°ì¡´ ë‹¨ì¼ í‚¤ì›Œë“œ ë¡œì§
                query_kw = f"""
                    SELECT *
                    FROM {table_name}
                    WHERE (
                        full_description ILIKE %s
                        OR artifact_name ILIKE %s
                        OR file_name ILIKE %s
                    )
                    {f'AND {exclude_conditions}' if exclude_conditions else ''};
                """
                cur.execute(query_kw, [f"%{kw}%", f"%{kw}%", f"%{kw}%"])

            rows = cur.fetchall()
            if rows:
                count = len(rows)
                hit_count += count
                total_hits += count
                print(f"      âœ… {count} match(es) for keyword: '{kw}'")
                matched_rows.extend([(table_name, tag, "keyword", kw, r) for r in rows])


        # -------------------------------
        # (2) event_id ê²€ìƒ‰
        # -------------------------------
        for eid in tag.get("event_id", []):
            try:
                if has_event_col:
                    query_eid = f"SELECT * FROM {table_name} WHERE CAST(event_id AS TEXT) ILIKE %s;"
                    cur.execute(query_eid, [f"%{eid}%"])
                else:
                    query_eid = f"""
                        SELECT *
                        FROM {table_name}
                        WHERE (
                            full_description ILIKE %s
                            OR artifact_name ILIKE %s
                            OR file_name ILIKE %s
                        );
                    """
                    cur.execute(query_eid, [f"%{eid}%", f"%{eid}%", f"%{eid}%"])

                rows = cur.fetchall()
                if rows:
                    count = len(rows)
                    hit_count += count
                    total_hits += count
                    print(f"      âœ… {count} match(es) for Event ID: {eid}")
                    matched_rows.extend([(table_name, tag, "event_id", str(eid), r) for r in rows])

            except psycopg2.errors.UndefinedColumn:
                conn.rollback()
                continue

        summary[table_name] = summary.get(table_name, 0) + hit_count

# ===============================
# 6ï¸âƒ£ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
# ===============================
print("\n=== ğŸ“Š Summary of Matches ===")
for table, count in summary.items():
    print(f"{table:<25} â†’ {count} hit(s)")

print(f"\nğŸ”¹ Total matches across all tags: {total_hits}")

# ===============================
# 7ï¸âƒ£ PostgreSQL ì—°ê²° ì¢…ë£Œ
# ===============================
cur.close()
conn.close()

# ===============================
# 8ï¸âƒ£ Milvus ì„¤ì •
# ===============================
COLLECTION_NAME = "tag_test"
DIM = 384
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

print("\nğŸš€ Connecting to Milvus...")
connections.connect("default", host="localhost", port="19530")

if utility.has_collection(COLLECTION_NAME):
    utility.drop_collection(COLLECTION_NAME)
    print(f"ğŸ§¹ Old collection '{COLLECTION_NAME}' dropped.")

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2000),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=DIM),
]
schema = CollectionSchema(fields, description="Forensic filtered search results")
collection = Collection(COLLECTION_NAME, schema)
print(f"âœ… Created collection: {COLLECTION_NAME}")
# ===============================
# 9ï¸âƒ£ SentenceTransformer ì„ë² ë”©
# ===============================
print(f"\nğŸ”„ Loading model: {MODEL_NAME}")
model = SentenceTransformer(MODEL_NAME)

texts = []
for table, tag, match_type, value, row in matched_rows:
    content = f"[{tag['category']}/{tag['subcategory']}] ({match_type}: {value}) " \
              + " ".join(str(c) for c in row if c)
    texts.append(content[:1900])

if texts:
    print(f"\nğŸ“¤ Encoding and inserting {len(texts)} rows into Milvus ...")
    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)


    BATCH_SIZE = 150  
    total = len(texts)
    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE

    for i in range(0, total, BATCH_SIZE):
        batch_texts = texts[i:i + BATCH_SIZE]
        batch_embeds = embeddings[i:i + BATCH_SIZE].tolist()
        print(f"ğŸš€ Inserting batch {i // BATCH_SIZE + 1}/{total_batches} ({len(batch_texts)} rows)")
        collection.insert([batch_texts, batch_embeds])

    collection.flush()
    print("âœ… All batches successfully inserted into Milvus!")
else:
    print("\nâš ï¸ No matched rows to insert into Milvus.")

print("\nğŸ Done.")
