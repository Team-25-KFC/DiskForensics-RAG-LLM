import psycopg2
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from sentence_transformers import SentenceTransformer
# ===============================
# 1ï¸âƒ£ DB ì„¤ì •
# ===============================
DB_CONFIG = {
    "host": "localhost",
    "dbname": "forensic_db",
    "user": "postgres",
    "password": "admin123",  # ì‹¤ì œ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
}

# ===============================
# 2ï¸âƒ£ íƒœê·¸ (RAG ê²°ê³¼)
# ===============================
tag = {
    "category": "Persistence",
    "subcategory": "Service_Install",
    "description": "ì„œë¹„ìŠ¤ ë“±ë¡ì„ í†µí•œ ì§€ì†ì„± í™•ë³´ ì—¬ë¶€ë¥¼ íƒì§€í•œë‹¤.",
    "keywords": [
      "Service Control Manager",
      "CreateService",
      "sc.exe",
      "svchost.exe"
    ],
    "event_id": [7045]
  }

# ===============================
# 3ï¸âƒ£ DB ì—°ê²°
# ===============================
conn = psycopg2.connect(**DB_CONFIG)
cur = conn.cursor()

# ===============================
# 4ï¸âƒ£ ëª¨ë“  forensic í…Œì´ë¸” ì¡°íšŒ
# ===============================
cur.execute("""
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema='public'
      AND table_name LIKE 'view_%'
    ORDER BY table_name;
""")
tables = [t[0] for t in cur.fetchall()]
print(f"ğŸ“‹ Found {len(tables)} tables:", ", ".join(tables))

matched_rows = []
summary = {}
total_hits = 0  # ì „ì²´ ì¼ì¹˜ ê°œìˆ˜

# ===============================
# 5ï¸âƒ£ ê° í…Œì´ë¸”ì—ì„œ keyword + event_id ê²€ìƒ‰
# ===============================
for table_name in tables:
    print(f"\nğŸ” Searching in table: {table_name}")

    # (1) ì»¬ëŸ¼ ëª©ë¡ í™•ì¸
    cur.execute("""
        SELECT column_name
        FROM information_schema.columns
        WHERE table_schema='public' AND table_name=%s;
    """, (table_name,))
    columns = [c[0] for c in cur.fetchall()]
    has_event_col = "event_id" in columns

    hit_count = 0  # í…Œì´ë¸”ë³„ ì´ ë§¤ì¹­ ê°œìˆ˜

    # (2) í‚¤ì›Œë“œ ê²€ìƒ‰
    for kw in tag["keywords"]:
        query_kw = f"""
            SELECT *
            FROM {table_name}
            WHERE (full_description ILIKE %s
               OR artifact_name ILIKE %s
               OR file_name ILIKE %s);
        """
        cur.execute(query_kw, [f"%{kw}%", f"%{kw}%", f"%{kw}%"])
        rows = cur.fetchall()
        if rows:
            count = len(rows)
            hit_count += count
            total_hits += count
            print(f"âœ… {count} match(es) for keyword: '{kw}'")
            matched_rows.extend([(table_name, "keyword", kw, r) for r in rows])

    # (3) event_id ê²€ìƒ‰ (ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ë¬¸ìì—´ ê²€ìƒ‰)
    for eid in tag.get("event_id", []):
        try:
            if has_event_col:
                query_eid = f"""
                    SELECT *
                    FROM {table_name}
                    WHERE CAST(event_id AS TEXT) ILIKE %s;
                """
                cur.execute(query_eid, [f"%{eid}%"])
            else:
                query_eid = f"""
                    SELECT *
                    FROM {table_name}
                    WHERE (
                        full_description ILIKE %s
                        OR artifact_name ILIKE %s
                        OR file_name ILIKE %s
                    );
                """
                cur.execute(query_eid, [f"%{eid}%", f"%{eid}%", f"%{eid}%"])
            rows = cur.fetchall()
            if rows:
                count = len(rows)
                hit_count += count
                total_hits += count
                print(f"âœ… {count} match(es) for Event ID: {eid}")
                matched_rows.extend([(table_name, "event_id", str(eid), r) for r in rows])
        except psycopg2.errors.UndefinedColumn:
            conn.rollback()
            continue

    # (4) ìš”ì•½ ì €ì¥
    summary[table_name] = hit_count

# ===============================
# 6ï¸âƒ£ ìš”ì•½ ì¶œë ¥
# ===============================
print("\n=== ğŸ“Š Summary of Matches ===")
for table, count in summary.items():
    print(f"{table:<25} â†’ {count} hit(s)")

# ===============================
# 7ï¸âƒ£ ì „ì²´ ê²°ê³¼ ìš”ì•½
# ===============================
total_tables = len(tables)
if total_hits > 0:
    print(f"\nâœ… ì´ {total_tables}ê°œ í…Œì´ë¸”ì„ íƒìƒ‰í•œ ê²°ê³¼, {total_hits}ê°œì˜ ì¼ì¹˜ í•­ëª©ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
else:
    print(f"\nâŒ ì´ {total_tables}ê°œ í…Œì´ë¸”ì„ íƒìƒ‰í–ˆì§€ë§Œ, ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ===============================
# 8ï¸âƒ£ ì„¸ë¶€ ê²°ê³¼ ì¶œë ¥
# ===============================
if matched_rows:
    print("\n=== ğŸ¯ Detailed Matched Rows ===")
    for table, match_type, value, row in matched_rows:
        print(f"[{table}] {match_type}='{value}' â†’ {row}")

# ===============================
# 9ï¸âƒ£ ì¢…ë£Œ
# ===============================
cur.close()
conn.close()
# ===============================
# ğŸ”¹ Milvus ì„¤ì •
# ===============================
COLLECTION_NAME = "tag_test"
DIM = 384
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"


print("\nğŸš€ Connecting to Milvus...")
connections.connect("default", host="localhost", port="19530")

# ê¸°ì¡´ ì»¬ë ‰ì…˜ ìˆìœ¼ë©´ ì‚­ì œ í›„ ì¬ìƒì„± (ì›í•˜ë©´ ìœ ì§€í•˜ë„ë¡ ë³€ê²½ ê°€ëŠ¥)
if utility.has_collection(COLLECTION_NAME):
    utility.drop_collection(COLLECTION_NAME)
    print(f"ğŸ§¹ Old collection '{COLLECTION_NAME}' dropped.")

# ì»¬ë ‰ì…˜ ìƒì„± (id, vector, textë§Œ)
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2000),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=DIM),
]
schema = CollectionSchema(fields, description="Forensic filtered search results")
collection = Collection(COLLECTION_NAME, schema)
print(f"âœ… Created collection: {COLLECTION_NAME}")

# ===============================
# ğŸ”¹ SentenceTransformer ì„ë² ë”©
# ===============================
print(f"\nğŸ”„ Loading model: {MODEL_NAME}")
model = SentenceTransformer(MODEL_NAME)

# PostgreSQL ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ìƒì„±
texts = []
for table, match_type, value, row in matched_rows:
    # íƒœê·¸ ì •ë³´ + ë§¤ì¹­ ì •ë³´ + ì „ì²´ í–‰ ë‚´ìš© ì „ë¶€ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
    content = f"[{tag['category']}/{tag['subcategory']}] ({match_type}: {value}) " \
              + " ".join(str(c) for c in row if c)
    texts.append(content[:1900])  # ê¸¸ì´ ì œí•œ

if not texts:
    print("\nâš ï¸ No matched rows to insert into Milvus.")
else:
    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)

   # ===============================
# ğŸ”¹ Milvus ì—…ë¡œë“œ
# ===============================
print(f"\nğŸ“¤ Inserting {len(texts)} rows into Milvus ({COLLECTION_NAME}) ...")

# âœ… idëŠ” auto_id=True ì´ë¯€ë¡œ ì œê±°
collection.insert([
    texts,                   # text
    embeddings.tolist(),      # vector
])

collection.flush()
print("âœ… Data successfully inserted into Milvus!")
print("\nğŸ Done.")